---
title: "MARCER: Multimodal Augmented Reality for Composing and Executing Robot Tasks"
collection: publications
permalink: /publications/marcer
authors: <b>Maitrey Gramopadhye<sup>*</sup></b>, Bryce Ikeda<sup>*</sup>, LillyAnn Nekervis, Daniel Szafir
excerpt: 'In this paper, we design and evaluate a novel interactive and multimodal end-user robot programming system. MARCER combines Trigger-Action Programming, Large Language Models and Augmented Re- ality to allow users to author and visualize reactive robot behavior.'
date: 2025-03-01
venue: 'ACM/IEEE International Conference on Human Robot Interaction (HRI), 2025'
paperurl: 'https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10974232'
---

<style>
/* Style the counter cards */
.column {
  float: left;
  width: 25%;
  padding: 0 10px;
}

.card {
<!--   box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.2); /* this adds the "card" effect */ -->
  padding: 16px;
<!--   text-align: center; -->
<!--   background-color: #f1f1f1; -->
}
  
a:link {
  text-decoration: none;
}
</style>

<p>Maitrey Gramopadhye<sup>*</sup>, Bryce Ikeda<sup>*</sup>, LillyAnn Nekervis, Daniel Szafir</p>
<br>
<div class="card">
  <video width="100%" controls>
    <source src="/images/demo_540.mp4" type="video/mp4">
  Your browser does not support the video tag.
  </video>
</div>
<br>

[View the paper here](https://maitreygram.github.io/papers/Maitrey_HIRL.pdf)

Large Language Models have had a notable surge in popularity in task planning for embodied robots. However, most approaches have the robot operating in isolation with minimal collaboration with humans. In this paper, we design a system that enables people to interact with an intelligent robot. We conduct a human subjects study to gain insights into the participantsâ€™ mental model, and whether the comprehensive abilities of LLMs encourage the users to adopt a collaborative role when working with the robot for long-horizon tasks.
